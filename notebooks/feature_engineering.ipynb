{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totiela/vk-ml-time-series-test-task/blob/main/notebooks/feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт библиотек и загрузка данных"
      ],
      "metadata": {
        "id": "h86wND91jolD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка неообходимых библиотек\n",
        "!pip install -q tsfresh"
      ],
      "metadata": {
        "id": "qJN1N9yDjqGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wSO8CaubjAIT"
      },
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "# Отключение всех предупреждений\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9pwzSNBjATO",
        "outputId": "89fdab8e-100a-43ce-e5ca-c475d3638b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vk-ml-time-series-test-task'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 130 (delta 23), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 47.81 MiB | 8.03 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "/content/vk-ml-time-series-test-task\n"
          ]
        }
      ],
      "source": [
        "# Клонируем репозитоиий\n",
        "!git clone https://github.com/totiela/vk-ml-time-series-test-task.git\n",
        "%cd vk-ml-time-series-test-task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "akMIEZZRjAVw"
      },
      "outputs": [],
      "source": [
        "# Загружаем тренировочный и тестовый датафреймы\n",
        "train_path = \"data/raw/train.parquet\"\n",
        "test_path = \"data/raw/test.parquet\"\n",
        "\n",
        "train_df = pd.read_parquet(train_path)\n",
        "test_df = pd.read_parquet(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Генерация признаков"
      ],
      "metadata": {
        "id": "17tMUx_E8YES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для извлечения признаков библиотекой tsfresh\n",
        "def generate_features(df, column_id='id', column_dates='dates', column_values='values', date_format='%Y-%m-%d'):\n",
        "    \"\"\"\n",
        "    Преобразует временные ряды в длинный формат, генерирует и обрабатывает признаки.\n",
        "\n",
        "    Параметры:\n",
        "    - df (pd.DataFrame): Исходный датафрейм с временными рядами.\n",
        "    - column_id (str): Название колонки с уникальными идентификаторами.\n",
        "    - column_dates (str): Название колонки с датами наблюдений.\n",
        "    - column_values (str): Название колонки с соответствующими значениями.\n",
        "    - date_format (str): Формат дат для преобразования в datetime, по умолчанию '%Y-%m-%d'.\n",
        "\n",
        "    Возвращает:\n",
        "    - pd.DataFrame: Датафрейм с сгенерированными признаками.\n",
        "    \"\"\"\n",
        "\n",
        "    # Преобразование в длинный формат\n",
        "    records = []\n",
        "    for index, row in df.iterrows():\n",
        "        for date, value in zip(row[column_dates], row[column_values]):\n",
        "            records.append({column_id: row[column_id], 'date': date, 'value': value})\n",
        "\n",
        "    long_df = pd.DataFrame(records)\n",
        "    long_df['date'] = pd.to_datetime(long_df['date'], format=date_format)\n",
        "    long_df = long_df.fillna(0)\n",
        "\n",
        "    # Генерация признаков\n",
        "    extracted_features = extract_features(\n",
        "        long_df,\n",
        "        column_id=column_id,\n",
        "        column_sort='date',\n",
        "        column_value='value'\n",
        "    )\n",
        "\n",
        "    # Иммутация пропущенных значений\n",
        "    imputed_features = impute(extracted_features)\n",
        "\n",
        "    # Приведение к упорядоченному индексу\n",
        "    imputed_features = imputed_features.sort_index()\n",
        "\n",
        "    return imputed_features"
      ],
      "metadata": {
        "id": "_kEvsg5M8a0x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Применение функции к тренировочным и тестовым данным (выполняется долго)\n",
        "imputed_features_test = generate_features(test_df)\n",
        "imputed_features_train = generate_features(train_df)"
      ],
      "metadata": {
        "id": "C3mNEqBr9VrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Всего получили более 700 признаков, но я отобрал топ-125 и топ-100 лучших признаков с помощью рекурсивного отбора значимости для модели catboost\n",
        "\n",
        "# Загружаем данные из JSON-файла\n",
        "with open(\"src/top_features.json\", \"r\") as f:\n",
        "    features = json.load(f)\n",
        "\n",
        "# Доступ к спискам признаков\n",
        "top_100_features = features[\"top_100\"]\n",
        "top_125_features = features[\"top_125\"]\n",
        "\n",
        "# Проверяем результат\n",
        "print(\"Top 100 Features:\", top_100_features)\n",
        "print(\"Top 125 Features:\", top_125_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YYkewMOAPjc",
        "outputId": "33c03d3c-7bda-4d8b-8681-81773c29e8c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 100 Features: ['value__variance_larger_than_standard_deviation', 'value__sum_values', 'value__abs_energy', 'value__mean_change', 'value__mean_second_derivative_central', 'value__median', 'value__mean', 'value__length', 'value__standard_deviation', 'value__variation_coefficient', 'value__variance', 'value__skewness', 'value__root_mean_square', 'value__longest_strike_below_mean', 'value__last_location_of_maximum', 'value__last_location_of_minimum', 'value__first_location_of_minimum', 'value__percentage_of_reoccurring_values_to_all_values', 'value__percentage_of_reoccurring_datapoints_to_all_datapoints', 'value__sum_of_reoccurring_values', 'value__sum_of_reoccurring_data_points', 'value__ratio_value_number_to_time_series_length', 'value__sample_entropy', 'value__quantile__q_0.1', 'value__quantile__q_0.3', 'value__quantile__q_0.4', 'value__quantile__q_0.6', 'value__quantile__q_0.7', 'value__quantile__q_0.8', 'value__quantile__q_0.9', 'value__autocorrelation__lag_2', 'value__autocorrelation__lag_3', 'value__partial_autocorrelation__lag_1', 'value__index_mass_quantile__q_0.8', 'value__index_mass_quantile__q_0.9', 'value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_1__w_2__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_2__w_2__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_9__w_2__widths_(2, 5, 10, 20)', 'value__ar_coefficient__coeff_1__k_10', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0', 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0', 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.2', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.4', 'value__fft_coefficient__attr_\"real\"__coeff_0', 'value__fft_coefficient__attr_\"real\"__coeff_1', 'value__fft_coefficient__attr_\"real\"__coeff_2', 'value__fft_coefficient__attr_\"real\"__coeff_3', 'value__fft_coefficient__attr_\"imag\"__coeff_1', 'value__fft_coefficient__attr_\"imag\"__coeff_2', 'value__fft_coefficient__attr_\"imag\"__coeff_3', 'value__fft_coefficient__attr_\"imag\"__coeff_4', 'value__fft_coefficient__attr_\"imag\"__coeff_5', 'value__fft_coefficient__attr_\"imag\"__coeff_6', 'value__fft_coefficient__attr_\"imag\"__coeff_10', 'value__fft_coefficient__attr_\"abs\"__coeff_0', 'value__fft_coefficient__attr_\"angle\"__coeff_0', 'value__fft_coefficient__attr_\"angle\"__coeff_1', 'value__fft_coefficient__attr_\"angle\"__coeff_2', 'value__fft_coefficient__attr_\"angle\"__coeff_3', 'value__fft_coefficient__attr_\"angle\"__coeff_4', 'value__fft_coefficient__attr_\"angle\"__coeff_5', 'value__fft_aggregated__aggtype_\"skew\"', 'value__fft_aggregated__aggtype_\"kurtosis\"', 'value__value_count__value_-1', 'value__range_count__max_0__min_-1000000000000.0', 'value__approximate_entropy__m_2__r_0.1', 'value__approximate_entropy__m_2__r_0.3', 'value__approximate_entropy__m_2__r_0.5', 'value__approximate_entropy__m_2__r_0.7', 'value__approximate_entropy__m_2__r_0.9', 'value__linear_trend__attr_\"rvalue\"', 'value__linear_trend__attr_\"intercept\"', 'value__linear_trend__attr_\"slope\"', 'value__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"max\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"max\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_50__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"', 'value__number_crossing_m__m_0', 'value__energy_ratio_by_chunks__num_segments_10__segment_focus_8', 'value__energy_ratio_by_chunks__num_segments_10__segment_focus_9', 'value__count_below__t_0', 'value__lempel_ziv_complexity__bins_2', 'value__lempel_ziv_complexity__bins_5', 'value__lempel_ziv_complexity__bins_10', 'value__lempel_ziv_complexity__bins_100', 'value__permutation_entropy__dimension_7__tau_1', 'value__mean_n_absolute_max__number_of_maxima_7']\n",
            "Top 125 Features: ['value__variance_larger_than_standard_deviation', 'value__sum_values', 'value__abs_energy', 'value__mean_change', 'value__mean_second_derivative_central', 'value__median', 'value__mean', 'value__length', 'value__standard_deviation', 'value__variation_coefficient', 'value__variance', 'value__skewness', 'value__root_mean_square', 'value__longest_strike_below_mean', 'value__last_location_of_maximum', 'value__last_location_of_minimum', 'value__first_location_of_minimum', 'value__percentage_of_reoccurring_values_to_all_values', 'value__percentage_of_reoccurring_datapoints_to_all_datapoints', 'value__sum_of_reoccurring_values', 'value__sum_of_reoccurring_data_points', 'value__ratio_value_number_to_time_series_length', 'value__sample_entropy', 'value__maximum', 'value__benford_correlation', 'value__cid_ce__normalize_True', 'value__quantile__q_0.1', 'value__quantile__q_0.3', 'value__quantile__q_0.4', 'value__quantile__q_0.6', 'value__quantile__q_0.7', 'value__quantile__q_0.8', 'value__quantile__q_0.9', 'value__autocorrelation__lag_1', 'value__autocorrelation__lag_2', 'value__autocorrelation__lag_3', 'value__partial_autocorrelation__lag_1', 'value__index_mass_quantile__q_0.8', 'value__index_mass_quantile__q_0.9', 'value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_1__w_2__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_1__w_5__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_2__w_2__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_8__w_2__widths_(2, 5, 10, 20)', 'value__cwt_coefficients__coeff_14__w_20__widths_(2, 5, 10, 20)', 'value__ar_coefficient__coeff_1__k_10', 'value__ar_coefficient__coeff_2__k_10', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0', 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0', 'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.0', 'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.8__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_1.0__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.0', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.4', 'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.6', 'value__fft_coefficient__attr_\"real\"__coeff_0', 'value__fft_coefficient__attr_\"real\"__coeff_1', 'value__fft_coefficient__attr_\"real\"__coeff_2', 'value__fft_coefficient__attr_\"real\"__coeff_3', 'value__fft_coefficient__attr_\"real\"__coeff_6', 'value__fft_coefficient__attr_\"imag\"__coeff_1', 'value__fft_coefficient__attr_\"imag\"__coeff_2', 'value__fft_coefficient__attr_\"imag\"__coeff_3', 'value__fft_coefficient__attr_\"imag\"__coeff_4', 'value__fft_coefficient__attr_\"imag\"__coeff_5', 'value__fft_coefficient__attr_\"imag\"__coeff_6', 'value__fft_coefficient__attr_\"imag\"__coeff_10', 'value__fft_coefficient__attr_\"abs\"__coeff_0', 'value__fft_coefficient__attr_\"angle\"__coeff_0', 'value__fft_coefficient__attr_\"angle\"__coeff_1', 'value__fft_coefficient__attr_\"angle\"__coeff_2', 'value__fft_coefficient__attr_\"angle\"__coeff_3', 'value__fft_coefficient__attr_\"angle\"__coeff_4', 'value__fft_coefficient__attr_\"angle\"__coeff_5', 'value__fft_coefficient__attr_\"angle\"__coeff_18', 'value__fft_aggregated__aggtype_\"variance\"', 'value__fft_aggregated__aggtype_\"skew\"', 'value__fft_aggregated__aggtype_\"kurtosis\"', 'value__value_count__value_0', 'value__value_count__value_1', 'value__value_count__value_-1', 'value__range_count__max_0__min_-1000000000000.0', 'value__approximate_entropy__m_2__r_0.1', 'value__approximate_entropy__m_2__r_0.5', 'value__approximate_entropy__m_2__r_0.7', 'value__approximate_entropy__m_2__r_0.9', 'value__linear_trend__attr_\"rvalue\"', 'value__linear_trend__attr_\"intercept\"', 'value__linear_trend__attr_\"slope\"', 'value__linear_trend__attr_\"stderr\"', 'value__agg_linear_trend__attr_\"rvalue\"__chunk_len_5__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"rvalue\"__chunk_len_50__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"max\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"max\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"min\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"slope\"__chunk_len_50__f_agg_\"mean\"', 'value__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"var\"', 'value__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"', 'value__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"var\"', 'value__number_crossing_m__m_0', 'value__energy_ratio_by_chunks__num_segments_10__segment_focus_6', 'value__energy_ratio_by_chunks__num_segments_10__segment_focus_8', 'value__energy_ratio_by_chunks__num_segments_10__segment_focus_9', 'value__count_above__t_0', 'value__lempel_ziv_complexity__bins_2', 'value__lempel_ziv_complexity__bins_3', 'value__lempel_ziv_complexity__bins_5', 'value__lempel_ziv_complexity__bins_10', 'value__lempel_ziv_complexity__bins_100', 'value__permutation_entropy__dimension_6__tau_1', 'value__permutation_entropy__dimension_7__tau_1', 'value__mean_n_absolute_max__number_of_maxima_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для добавления ручных признаков\n",
        "\n",
        "def extract_and_join_features(df, imputed_features):\n",
        "    \"\"\"\n",
        "    Вычисляет дополнительные признаки для временных рядов и объединяет их с переданными сгенерированными признаками.\n",
        "\n",
        "    Параметры:\n",
        "    - df (pd.DataFrame): Исходный датафрейм с временными рядами.\n",
        "    - imputed_features (pd.DataFrame): Датафрейм с ранее рассчитанными признаками.\n",
        "\n",
        "    Возвращает:\n",
        "    - pd.DataFrame: Датафрейм с объединенными ручными и сгенерированными признаками.\n",
        "\n",
        "    Описание:\n",
        "    - Вычисляет различные признаки на основе временных рядов, такие как:\n",
        "        - dates_count: количество значений в каждой временной серии.\n",
        "        - close_to_zero_diff: количество точек, близких к нулю по разнице значений.\n",
        "        - quarterly_mean: среднее значение первых 4-х месяцев.\n",
        "        - winter_percent и summer_percent: процент зимних и летних точек данных.\n",
        "        - zero_crossings: количество переходов через ноль.\n",
        "        - rolling_mean_X и rolling_std_X: скользящие средние и стандартное отклонение.\n",
        "        - increasing_trend и decreasing_trend: количество точек с трендом на увеличение и уменьшение.\n",
        "        - first_3_mean и last_3_mean: средние значения для первых и последних 3 значений ряда.\n",
        "        - start_end_ratio: соотношение последних и первых 3 значений ряда.\n",
        "        - seasonality_index: сезонный индекс, рассчитывающий сезонные изменения.\n",
        "\n",
        "    - Удаляет ненужные признаки ('dates', 'values', 'values_diff', 'id') и объединяет результат с `imputed_features`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Количество значений в каждой временной серии\n",
        "    df['dates_count'] = df['dates'].apply(lambda x: x.shape[0])\n",
        "\n",
        "    # Производные значения ряда\n",
        "    df['values_diff'] = df['values'].apply(lambda x: pd.Series(x).diff().dropna().round(4).to_numpy())\n",
        "\n",
        "    # Количество точек, близких к нулю\n",
        "    df['close_to_zero_diff'] = df['values_diff'].apply(lambda x: (np.abs(x) < 0.1).sum() if x.size > 0 else np.nan)\n",
        "\n",
        "    # Среднее значение первых 4-х месяцев\n",
        "    df['quarterly_mean'] = df['values'].apply(lambda x: np.mean(x[:4]) if len(x) >= 4 else np.nan)\n",
        "\n",
        "    # Процент зимних и летних точек данных\n",
        "    df['winter_percent'] = df['dates'].apply(lambda dates: np.mean([d.month in [12, 1, 2] for d in dates if pd.notnull(d)]) * 100)\n",
        "    df['summer_percent'] = df['dates'].apply(lambda dates: np.mean([d.month in [6, 7, 8] for d in dates if pd.notnull(d)]) * 100)\n",
        "\n",
        "    # Количество переходов через ноль\n",
        "    df['zero_crossings'] = df['values'].apply(lambda x: np.sum(np.diff(np.sign(x)) != 0) if len(x) > 1 else 0)\n",
        "\n",
        "    # Скользящие средние по значениям\n",
        "    df['rolling_mean_3'] = df['values'].apply(lambda x: pd.Series(x).rolling(3).mean().iloc[-1] if len(x) >= 3 else np.nan)\n",
        "    df['rolling_mean_6'] = df['values'].apply(lambda x: pd.Series(x).rolling(6).mean().iloc[-1] if len(x) >= 6 else np.nan)\n",
        "    df['rolling_mean_12'] = df['values'].apply(lambda x: pd.Series(x).rolling(window=12).mean().iloc[-1] if len(x) >= 12 else np.nan)\n",
        "    df['rolling_std_12'] = df['values'].apply(lambda x: pd.Series(x).rolling(window=12).std().iloc[-1] if len(x) >= 12 else np.nan)\n",
        "\n",
        "    # Тренды на увеличение и уменьшение\n",
        "    df['increasing_trend'] = df['values'].apply(lambda x: (np.diff(x) > 0).sum())\n",
        "    df['decreasing_trend'] = df['values'].apply(lambda x: (np.diff(x) < 0).sum())\n",
        "\n",
        "    # Среднее значение первых и последних 3 значений\n",
        "    df['first_3_mean'] = df['values'].apply(lambda x: np.mean(x[:3]))\n",
        "    df['last_3_mean'] = df['values'].apply(lambda x: np.mean(x[-3:]))\n",
        "\n",
        "    # Соотношение между последними и первыми 3 значениями\n",
        "    df['start_end_ratio'] = df['last_3_mean'] / (df['first_3_mean'] + 1e-5)\n",
        "\n",
        "    # Сезонный индекс (для сезонных изменений)\n",
        "    def seasonal_effect(values, dates):\n",
        "        months_values = {m: [] for m in range(1, 13)}\n",
        "        for val, date in zip(values, dates):\n",
        "            months_values[date.month].append(val)\n",
        "        return np.std([np.mean(months) for months in months_values.values() if months])\n",
        "\n",
        "    df['seasonality_index'] = df.apply(lambda x: seasonal_effect(x['values'], x['dates']), axis=1)\n",
        "\n",
        "    # Отбор рассчитанных признаков, исключая 'dates', 'values', 'id, 'values_diff и Join с imputed_features\n",
        "    new_df = df.drop(['dates', 'values', 'values_diff', 'id'], axis=1)\n",
        "    result_df = new_df.join(imputed_features)\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "7YnGCshZJqXi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем необходимые итоговые признаки для тренировочных и тестовых данных\n",
        "test_116_features = extract_and_join_features(test_df, imputed_features_test[top_100_features])\n",
        "test_141_features = extract_and_join_features(test_df, imputed_features_test[top_125_features])\n",
        "\n",
        "train_116_features = extract_and_join_features(train_df, imputed_features_train[top_100_features])\n",
        "train_141_features = extract_and_join_features(train_df, imputed_features_train[top_125_features])"
      ],
      "metadata": {
        "id": "hE_C7e6HJswe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружаем итоговые датафреймы в формате .parquet\n",
        "test_116_features.to_parquet('test_116_features.parquet')\n",
        "test_141_features.to_parquet('test_141_features.parquet')\n",
        "\n",
        "train_116_features.to_parquet('train_116_features.parquet')\n",
        "train_141_features.to_parquet('test_141_features.parquet')"
      ],
      "metadata": {
        "id": "Km7KhP7F3brG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnL/eGvkY8Xvv6EBRIRvle",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}